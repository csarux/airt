---
title: "Inteligencia artificial en radioterapia"
subtitle: Simposio de T√©cnicos. Congreso conjunto SEFM SEPR. Toledo 2025
format: 
  clean-revealjs:
    logo: images/2505-SEFM-SEPR_Toledo_400x122-400x122.png
    footer: "IA en Radioterapia"
  pptx: {}
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: C√©sar Rodr√≠guez
    email: cesar.rodriguez@salud.madrid.org
    affiliations: Hospital Universitario de Fuenlabrada
css: styles.css
---


# ¬øQu√© es la inteligencia artificial?

---

## 1. Definici√≥n de IA {.smaller}

> La [**inteligencia artificial**]{.alert} (IA) es una rama de la inform√°tica que [**permite a las m√°quinas imitar funciones cognitivas**]{.alert} humanas como aprender, razonar, resolver problemas o tomar decisiones.

### Ejemplos cotidianos de IA

- Filtros de spam en el correo.
- Recomendaciones en Netflix o Spotify.
- Traductores autom√°ticos.
- Chatbots.
- Detecci√≥n de tumores en mamograf√≠as.

:::{.callout-note icon="true"}
## Cotidaneidad de la IA
Convivimos con la IA todos los d√≠as, incluso sin darnos cuenta. En medicina, puede ser una gran aliada.
:::

---

## 2. ¬øEn qu√© se diferencia de un software tradicional?

| Caracter√≠stica         | Software tradicional             | Inteligencia Artificial                |
|------------------------|----------------------------------|----------------------------------------|
| Instrucciones          | Programadas expl√≠citamente       | Aprende de datos                       |
| Capacidad de adaptaci√≥n| Fija                             | Se adapta con entrenamiento            |
| Ejemplo en radioterapia| C√°lculo de dosis con f√≥rmulas    | Segmentaci√≥n autom√°tica                |{.smaller}

> ‚úÖ **Analog√≠a culinaria**:  
> El software tradicional es como una receta;  
> la IA es como un cocinero que aprende probando.

---

## 3. Tipos principales de IA{.smaller}

::: {.columns}
:::: {.column}
### IA simb√≥lica

- Basada en reglas l√≥gicas.
- Utiliza sistemas expertos.
- Es la forma m√°s antigua de IA.

### Machine Learning (ML)

- Aprende patrones a partir de datos.
- Necesita entrenamiento con muchos ejemplos.
- Se ha convertido en el n√∫cleo de la IA moderna.

### Deep Learning (DL)

- Subconjunto de ML.
- Utiliza redes neuronales profundas.
- Muy eficaz en imagen m√©dica.

::::
:::: {.column .bottom-align}
![](images/MachineLearning_DeepLearning.png)
::::
:::

# Ejemplos

---
 
### Software tradicional. C√°lculo de la dosis

::: {.smaller-columns}
::: {.columns}
:::: {.column width="30%"}
![](images/CalculoDosis.png)
::::
:::: {.column width="70%"}
$$
\begin{aligned}
\Omega_\gamma \cdot \nabla \Phi_\gamma(r, \Omega_\gamma, E_\gamma) = \\
\rho_e(r) \int_0^\infty \int_{4\pi} \tilde{\sigma}_{C,\gamma}(E'_\gamma, E_\gamma, \Omega'_\gamma \cdot \Omega_\gamma) 
\Phi_\gamma(r, \Omega'_\gamma, E'_\gamma) d\Omega'_\gamma dE'_\gamma
\\
- \rho_e(r) \sigma_{\text{totC},\gamma}(E_\gamma) \Phi_\gamma(r, \Omega_\gamma, E_\gamma)
\end{aligned}
$$

Ecuaci√≥n de Boltzmann de transporte de fotones

:::: 
:::
:::

- Problemas complejos que se pueden reducir a algoritmos programables
- La velocidad de c√°lculo de la m√°quina supera completamente lo que es realizable por un ser humano

:::{.callout-tip icon="true"}
## Paradigma 
Sabemos c√≥mo funciona y **funciona** (*para lo que est√° programado*)
:::

---

### IA tradicional (√°rboles l√≥gicos). Reconocimiento de patrones

::: {.columns}
:::: {.column width="50%"}
![Reconocimiento de caracteres y facial](images/handwrittendigits.png)
::::
:::: {.column width="50%"}
![](images/Jose.jpg){height="100px"} ![](images/Cesar.jpg){height="100px"} ![](images/Gema.jpg){height="100px"} ![](images/Eva.jpg){height="100px"} 

:::: 
:::

- La complejidad del problema crece tan r√°pidamente que son necesarias estructuras muy complicadas y muchos recursos.
- El humano supera con cierta facilidad los resultados de la m√°quina

:::{.callout-important icon="true"}
## Paradigma 
Sabemos c√≥mo funciona pero **no funciona** 
:::

# ¬øC√≥mo podemos hacer *pensar* a una m√°quina?

---

## Problemas de minimizaci√≥n
### Fundamentos matem√°ticos para el entrenamiento de sistemas

```{python}
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Datos simulados: precio de vivienda (en miles de euros) vs superficie (m¬≤)
np.random.seed(123)
m_true = 3.  # precio por m¬≤ en miles de euros
b_true = 100.0  # precio base (m√≠nimo, en miles de euros)
x = np.linspace(30, 150, 20)  # superficies entre 30 m¬≤ y 150 m¬≤
y = m_true * x + b_true + np.random.normal(scale=20.0, size=len(x))  # precios con ruido

# Rango de valores de pendiente (precio por m¬≤)
m_values = np.linspace(m_true - 2, m_true + 2, 50)
J_values = [np.sum((y - (m * x + b_true))**2) for m in m_values]

# Crear figura con subgr√°ficos
fig = make_subplots(rows=1, cols=2, subplot_titles=["Ajuste lineal: Precio vs Superficie", "Funci√≥n de coste J(m)"])

# A√±adir trazas fijas (siempre visibles)
fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name='Datos reales', marker=dict(color='black')), row=1, col=1)
fig.add_trace(go.Scatter(x=m_values, y=J_values, mode='lines', name='Funci√≥n de coste J(m)', line=dict(color='black')), row=1, col=2)

# Trazas din√°micas iniciales
m0 = m_values[0]
y_fit0 = m0 * x + b_true
J0 = J_values[0]

ajuste_inicial = go.Scatter(x=x, y=y_fit0, mode='lines', name='Ajuste lineal', line=dict(color='red'))
punto_J = go.Scatter(x=[m0], y=[J0], mode='markers', name='Valor de J', marker=dict(color='red', size=10))

fig.add_trace(ajuste_inicial, row=1, col=1)
fig.add_trace(punto_J, row=1, col=2)

# Frames para animar
frames = []

for i, m in enumerate(m_values):
    y_fit = m * x + b_true
    J = J_values[i]
    frame = go.Frame(
        data=[
            # Puntos originales (subplot 1,1)
            go.Scatter(x=x, y=y, mode='markers', marker=dict(color='black'),
                       xaxis='x1', yaxis='y1'),

            # L√≠nea de ajuste (subplot 1,1)
            go.Scatter(x=x, y=y_fit, mode='lines', line=dict(color='red'),
                       xaxis='x1', yaxis='y1'),

            # Curva de funci√≥n de coste J(m) (subplot 1,2)
            go.Scatter(x=m_values, y=J_values, mode='lines', line=dict(color='black'),
                       xaxis='x2', yaxis='y2'),

            # Punto rojo J(m) (subplot 1,2)
            go.Scatter(x=[m], y=[J], mode='markers', marker=dict(color='red', size=10),
                       xaxis='x2', yaxis='y2'),
        ],
        name=str(round(m, 2))
    )
    frames.append(frame)

# Slider
steps = [dict(method="animate",
              args=[[str(round(m, 2))],
                    dict(mode="immediate",
                         frame=dict(duration=0, redraw=True),
                         transition=dict(duration=0))],
              label=str(round(m, 2)))
         for m in m_values]

sliders = [dict(
    steps=steps,
    transition=dict(duration=0),
    x=0.1,
    y=0,
    currentvalue=dict(font=dict(size=16), prefix="Precio por m¬≤ = ", visible=True, xanchor='center'),
    len=0.8
)]

# Aplicar layout con solo el slider
fig.update_layout(
    sliders=sliders,
    height=500,
    width=1000
)

# Asignar los frames directamente
fig.frames = frames

# Etiquetas de ejes
fig.update_xaxes(title_text="Superficie (m¬≤)", row=1, col=1)
fig.update_yaxes(title_text="Precio (miles de euros)", row=1, col=1)
fig.update_xaxes(title_text="Precio por m¬≤ (miles de euros)", row=1, col=2)
fig.update_yaxes(title_text="J(m)", row=1, col=2)

fig.show()

```
---

### Elementos clave 

- El sistema establece el modelo minimizando una ***funci√≥n de coste*** que tiene que ser definida previamente

:::{.callout-tip icon="true"}
## C√°lculos de minimizaci√≥n 
La minimizaci√≥n es proceso programable por los procedimientos de software tradicional
:::

:::{.callout-important icon="true"}
## Importancia del modelo
El modelo nos permite **hacer predicciones** reduciendo la influencia de variables ocultas
:::

#### Dificultades con modelos que dependen de varias variables
- No todas las variables que podemos introducir en el modelo lo *sujetan* con la misma intensidad
- Algunas variables presentan correlaciones, es decir, la variaci√≥n de una implica la variaci√≥n de otra.


---

### Varias variables con diferentes correlaciones

```{python}

import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

np.random.seed(123)

# Simulaci√≥n 1: Precio vs Superficie (alta correlaci√≥n)
m1_true = 3.0  # mil ‚Ç¨/m¬≤
b1_true = 100.0
x1 = np.linspace(50, 150, 20)  # m¬≤
y1 = m1_true * x1 + b1_true + np.random.normal(scale=15.0, size=len(x1))

# Simulaci√≥n 2: Precio vs Altura (menor correlaci√≥n)
m2_true = 5.0  # mil ‚Ç¨/planta
b2_true = 200.0
x2 = np.linspace(1, 20, 20)  # plantas
y2 = m2_true * x2 + b2_true + np.random.normal(scale=40.0, size=len(x2))

# Ajustes
m1_fit, b1_fit = np.polyfit(x1, y1, 1)
y1_fit = m1_fit * x1 + b1_fit

m2_fit, b2_fit = np.polyfit(x2, y2, 1)
y2_fit = m2_fit * x2 + b2_fit

# Funciones de coste con rango de 5 unidades
m_values1 = np.linspace(m1_fit - 2.5, m1_fit + 2.5, 100)
J_values1 = [np.sum((y1 - (m * x1 + b1_true))**2) for m in m_values1]

m_values2 = np.linspace(m2_fit - 2.5, m2_fit + 2.5, 100)
J_values2 = [np.sum((y2 - (m * x2 + b2_true))**2) for m in m_values2]

# Crear figura con 4 subgr√°ficos
fig = make_subplots(rows=2, cols=2, subplot_titles=[
    "Precio vs Superficie",
    "Funci√≥n de coste J(m): Superficie",
    "Precio vs Altura",
    "Funci√≥n de coste J(m): Altura"
])

# Arriba izquierda: Ajuste superficie
fig.add_trace(go.Scatter(x=x1, y=y1, mode='markers', name='Datos superficie', marker=dict(color='black')), row=1, col=1)
fig.add_trace(go.Scatter(x=x1, y=y1_fit, mode='lines', name='Ajuste superficie', line=dict(color='red')), row=1, col=1)

# Arriba derecha: Coste superficie
fig.add_trace(go.Scatter(x=m_values1, y=J_values1, mode='lines', name='J(m): superficie', line=dict(color='black')), row=1, col=2)

# Abajo izquierda: Ajuste altura
fig.add_trace(go.Scatter(x=x2, y=y2, mode='markers', name='Datos altura', marker=dict(color='black')), row=2, col=1)
fig.add_trace(go.Scatter(x=x2, y=y2_fit, mode='lines', name='Ajuste altura', line=dict(color='red')), row=2, col=1)

# Abajo derecha: Coste altura
fig.add_trace(go.Scatter(x=m_values2, y=J_values2, mode='lines', name='J(m): altura', line=dict(color='black')), row=2, col=2)

# Etiquetas
fig.update_xaxes(title_text="Superficie (m¬≤)", row=1, col=1)
fig.update_yaxes(title_text="Precio (miles de ‚Ç¨)", row=1, col=1)
fig.update_xaxes(title_text="Pendiente m (mil ‚Ç¨/m¬≤)", row=1, col=2)
fig.update_yaxes(title_text="J(m)", row=1, col=2)

fig.update_xaxes(title_text="Altura (plantas)", row=2, col=1)
fig.update_yaxes(title_text="Precio (miles de ‚Ç¨)", row=2, col=1)
fig.update_xaxes(title_text="Pendiente m (mil ‚Ç¨/planta)", row=2, col=2)
fig.update_yaxes(title_text="J(m)", row=2, col=2)

fig.update_yaxes(range=[0, 1.e6], row=1, col=2)
fig.update_yaxes(range=[0, 1.e6], row=2, col=2)

fig.update_layout(
    height=650,
    width=800,
    showlegend=False
)

fig.show()


```

---

### **Overfitting** (sobreajuste)

```{python}

import numpy as np
import plotly.graph_objects as go

# Datos originales: precio vs superficie
np.random.seed(123)
m_true = 3.0  # mil ‚Ç¨/m¬≤
b_true = 100.0
x = np.linspace(50, 150, 20)
y = m_true * x + b_true + np.random.normal(scale=15.0, size=len(x))

# Ajuste polin√≥mico de grado alto (overfitting)
degree = len(x)
coefs = np.polyfit(x, y, degree)
poly = np.poly1d(coefs)

# Evaluar el modelo en una malla m√°s fina
x_fine = np.linspace(40, 160, 500)
y_poly = poly(x_fine)

# Crear figura
fig = go.Figure()

# Datos
fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name='Datos', marker=dict(color='black')))

# Ajuste polin√≥mico (overfitting)
fig.add_trace(go.Scatter(x=x_fine, y=y_poly, mode='lines', name='Modelo sobreajustado', line=dict(color='red', dash='dot')))

fig.update_yaxes(range=[200, 600])

# Layout
fig.update_layout(
    xaxis_title="Superficie (m¬≤)",
    yaxis_title="Precio (miles de ‚Ç¨)",
    width=800,
    height=500
)

fig.show()

```

- El modelo predice muy bien lo que ha aprendido
- Pierde la capacidad de predecir situaciones no entrenadas

# Ejemplos de minimizaci√≥n. Aplicaci√≥n a la radioterapia

## Optimaci√≥n de fluencias para tratamientos VMAT

![Tratamiento adyuvante de un hemicuello. Dosis de prescripci√≥n 66 Gy al primario y 56.1 Gy a las cadenas ganglionares](images/testORL.png)

---

##

![Definici√≥n del problema de optimizaci√≥n](images/DefinicionObjetivosOptimizacionVMAT.png)

> La **funci√≥n de coste no** es **√∫nica**.  
> Hay muchas funciones de coste que producen una soluci√≥n v√°lida;  
> se introduce variabilidad entre los planificadores.  
> Es dif√≠cil saber si la planificaci√≥n est√° realmente optimizada.  

---

## {.smaller}
#### Correlaciones entre par√°metros

![El tiroides en parte esta incluido en el PTV de cadenas](images/TiroidesRealista.PNG)

---

## {.smaller}
#### Correlaciones entre par√°metros

![Si forzamos el tiroides afectamos al PTV](images/TiroidesForzado.PNG)

# ¬øC√≥mo funciona una red neuronal artificial?

---

## {.smaller}

### Analog√≠a 
üß† **Red neuronal artificial =** üîß **F√°brica en cadena**

Cada capa recibe una entrada, la procesa y pasa el resultado a la siguiente.

Cada neurona hace una operaci√≥n: pondera entradas, suma, aplica una funci√≥n.

### Estructura t√≠pica

::: {.columns}
:::: {.column width="50%"}
- **Capa de entrada**: recibe la imagen o los datos.  
- **Capas ocultas**: transforman progresivamente la informaci√≥n.  
  - Convoluci√≥n  
  - Activaci√≥n (triggers)  
  - Normalizaci√≥n / reducci√≥n  
- **Capa de salida**: genera una predicci√≥n.
::::
:::: {.column width="50%"}
![](images/FullyConnectedLayers.webp){fig-align="center" }
::::
:::

---

### Detalles de las capas

#### üî∏ Capa de convoluci√≥n *(solo en redes de imagen)*

- Aplica peque√±os filtros que se desplazan por la imagen.  

![](images/diagrama_convolucion.png)

- Cada filtro detecta un patr√≥n espec√≠fico: borde, textura, forma‚Ä¶  
- Resultado: un mapa de activaci√≥n que destaca ese patr√≥n.  

---

## {.smaller}

#### Visualizaci√≥n de la salida de algunos filtros de convoluci√≥n


::: {.columns}
:::: {.column width="50%"}
![](images/BordesHorizontales.webp){fig-align="right" height="100px"}
::::
:::: {.column width="50%"}
![](images/BordesVerticales.webp){fig-align="left" height="100px"}
::::
:::

::: {.columns}
:::: {.column width="60%"}
![](images/SalidaFiltrosConvolucionPrimeraCapa.png){fig-align="center"}
::::
:::: {.column width="40%"}
üìå 

- En el dise√±o del modelo se fija el n√∫mero de filtros de convoluci√≥n
- Los detalles de cada filtro, sus valores concretos, se establecen durante el entrenamiento, son par√°metros ajustables del modelo
- En general la salida de los filtros de convoluci√≥n pueden tener una interpretaci√≥n no trivial para un ser humano
::::
:::

---

### üî∏ b) Funci√≥n de activaci√≥n (‚Äútrigger‚Äù)

- Imita el disparo neuronal: una funci√≥n no lineal ***decide si [la neurona se activa]{.alert}***.  
- Ejemplo: funci√≥n ReLU (Rectified Linear Unit):  
  - Salida = 0 si entrada < 0  
  - Salida = entrada si entrada ‚â• 0  

::: {.columns}
:::: {.column}
```{python}
import numpy as np
import matplotlib.pyplot as plt

# Definimos la funci√≥n ReLU
def relu(x):
    return np.maximum(0, x)

# Creamos un conjunto de valores
x = np.linspace(-10, 10, 1000)
y = relu(x)

# Graficamos
plt.figure(figsize=(4, 2.7))
plt.plot(x, y, label="ReLU(x)")
plt.axhline(0, color='gray', lw=0.5)
plt.axvline(0, color='gray', lw=0.5)
plt.title("Funci√≥n ReLU")
plt.xlabel("x")
plt.ylabel("ReLU(x)")
plt.grid(True)
plt.legend()
plt.show()

```
::::
:::: {.column}
```{python}
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from scipy.signal import convolve2d

# === Paso 1: Cargar y preparar la imagen ===
img_path = "images/Eva.jpg"  # Reemplaza con la ruta a tu imagen
img = Image.open(img_path).convert("L")  # Escala de grises
img = img.resize((256, 256))             # Redimensiona para facilidad
img_array = np.array(img) / 255.0        # Normaliza a [0,1]

# === Paso 2: Filtro de convoluci√≥n (bordes verticales estilo Sobel) ===
filtro = np.array([[1, 0, -1],
                   [2, 0, -2],
                   [1, 0, -1]])

# Aplicar convoluci√≥n 2D
conv_output = convolve2d(img_array, filtro, mode='same', boundary='symm')

# === Paso 3: Aplicar ReLU ===
relu_output = np.maximum(0, conv_output)

# === Paso 4: Mostrar los resultados ===
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.imshow(img_array, cmap='gray')
plt.title("Imagen original")
plt.axis('off')

plt.subplot(1, 3, 2)
plt.imshow(conv_output, cmap='gray')
plt.title("Convoluci√≥n (bordes)")
plt.axis('off')

plt.subplot(1, 3, 3)
plt.imshow(relu_output, cmap='gray')
plt.title("Tras ReLU")
plt.axis('off')

plt.tight_layout()
plt.show()

```
::::
:::

- Esto permite que la red aprenda relaciones complejas, no lineales.

---

### üî∏ c) Pooling (reducci√≥n)

- Reduce la dimensi√≥n de la informaci√≥n manteniendo lo importante.  
- Equivalente a hacer un ***[zoom out]{.alert}: pierde detalle, gana eficiencia***.  

::: {.columns}
:::: {.column}
![](images/PoolingMaxScheme.png)
::::
:::: {.column}
```{python}
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from scipy.signal import convolve2d
from skimage.measure import block_reduce

# === Paso 1: Cargar y preparar la imagen ===
img_path = "images/Eva.jpg"  # Reemplaza con tu imagen
img = Image.open(img_path).convert("L")
img = img.resize((256, 256))  # Tama√±o fijo
img_array = np.array(img) / 255.0

# === Paso 2: Aplicar filtro de bordes (Sobel horizontal) ===
filtro = np.array([[-1, 0, 1],
                   [-2, 0, 2],
                   [-1, 0, 1]])

conv_output = convolve2d(img_array, filtro, mode='same', boundary='symm')

# === Paso 3: Activaci√≥n ReLU ===
relu_output = np.maximum(0, conv_output)

# === Paso 4: MaxPooling 4x4 ===
# Reduce cada bloque de 4x4 a 1x1 (efecto "zoom out")
pooled_output = block_reduce(relu_output, block_size=(4, 4), func=np.max)

# === Paso 5: Visualizaci√≥n comparativa ===
plt.figure(figsize=(10, 5))

# Subgr√°fica 1: ReLU output original
plt.subplot(1, 2, 1)
plt.imshow(relu_output, cmap='gray')
plt.title("ReLU (alta resoluci√≥n)")
plt.axis('off')

# Subgr√°fica 2: ReLU tras MaxPooling (escalado al mismo tama√±o para comparaci√≥n)
plt.subplot(1, 2, 2)
plt.imshow(pooled_output, cmap='gray', extent=[0, relu_output.shape[1], relu_output.shape[0], 0])
plt.title("Tras MaxPooling 4x4")
plt.axis('off')

plt.tight_layout()
plt.show()

```
::::
:::

# ¬øC√≥mo aprende una red neuronal?

---

### üîπ a) Entrenamiento = Minimizar un error

- Se pasa una imagen por la red ‚Üí predicci√≥n.  
- Se compara con la etiqueta real ‚Üí funci√≥n de p√©rdida.  
- Se ajustan los pesos de las conexiones para reducir el error.  
- Este proceso se repite con millones de im√°genes.  

:::{.callout-tip icon="true"}
## Entrenamiento de una red neuronal
Entrenar una red neuronal es como hacer IMRT: queremos encontrar la mejor combinaci√≥n de pesos (par√°metros) que cumplan unos objetivos y minimicen una funci√≥n de coste.
:::

---

## Tipos de Aprendizaje en Machine Learning

::: {.columns}
:::: {.column}
### ‚úÖ Aprendizaje Supervisado
- Se entrena con **datos etiquetados**
- Cada entrada tiene una **respuesta conocida**
- El modelo aprende a **predecir la etiqueta** a partir de la entrada
::::
:::: {.column}
![](images/Chest-x-ray-images-from-Kaggle-dataset-a-Normal-lung-image-b-Bacterial-pneumonia.png)
::::
:::

---

### üîÑ Aprendizaje No Supervisado 
Se entrena con datos sin etiquetas

El objetivo es descubrir patrones ocultos, como agrupaciones o estructuras

::: {.columns}
:::: {.column}
![](images/george_clooney5.png){fig-align="center" height="300px"}
::::
:::: {.column}
![](images/cluster_personas_objetos.jpeg){fig-align="center" height="300px"}
::::
:::

---

### üß™ Aprendizaje Auto-supervisado 

Genera sus propias etiquetas a partir de los datos

Dise√±a tareas auxiliares para aprender representaciones √∫tiles

:::{.callout-tip icon="true"}
## Ejemplo de aprendizaje auto-supervisado
Enmascarar parte de una imagen y entrenar al modelo a reconstruirla
:::

---

## {.smaller} 

#### Resumen sobre los tipos de aprendizaje en IA

| Tipo               | Etiquetas reales requeridas     | Objetivo principal                 | Ejemplos comunes                                 |
|--------------------|----------------------------------|------------------------------------|--------------------------------------------------|
| Supervisado        | S√≠                              | Clasificaci√≥n, regresi√≥n           | Diagn√≥stico m√©dico, detecci√≥n de fallos          |
| No supervisado     | No                              | Agrupamiento, reducci√≥n            | An√°lisis exploratorio, clustering                |
| Auto-supervisado   | No (usa etiquetas derivadas)    | Aprendizaje de representaciones    | Preentrenamiento, NLP, visi√≥n artificial         |

---

## {.smaller}

#### Ejemplo: entrenamiento de una red neuronal de reconocimiento facial

Cuatro clases, 150 archivos de 128x128 en color, 

**Arquitectura de la red**

| Layer (type)                    | Output Shape           |       Param # |
|---------------------------------|------------------------|---------------|
| conv2d (Conv2D)                 | (None, 126, 126, 32)   |           896 |
| max_pooling2d (MaxPooling2D)    | (None, 63, 63, 32)     |             0 |
| conv2d_1 (Conv2D)               | (None, 61, 61, 64)     |        18,496 |
| max_pooling2d_1 (MaxPooling2D)  | (None, 30, 30, 64)     |             0 |
| flatten (Flatten)               | (None, 57600)          |             0 |
| dense (Dense)                   | (None, 128)            |     7,372,928 |
| dropout (Dropout)               | (None, 128)            |             0 |
| dense_1 (Dense)                 | (None, 4)              |           516 |

- N√∫mero de par√°metros ajustables (Memoria): **[7,392,836]{.alert} (28.20 MB)**
- Tiempo de entrenamiento en un Apple Silicon M2: **11.63 secs**

[**Exactitud del modelo: 96.67%**]{.alert}

---

:::{.callout-important icon="true"}
## Degeneraci√≥n del problema
El n√∫mero de par√°metros a ajustar es tan elevado que no es un problema sencillo de resolver. Necesitamos que el software de entrenamiento siga alguna estrategia que nos guie hacia una soluci√≥n v√°lida.
:::


### üîπ b) Optimizaci√≥n por retropropagaci√≥n

- Se calcula el error.  
- Se propaga hacia atr√°s a trav√©s de la red.  
- Se ajustan los pesos paso a paso con t√©cnicas como descenso de gradiente, actuando fundamentalmente sobre los par√°metros que se identifican m√°s relevantes.


# üß† Modelos de Inteligencia Artificial: Clasificaci√≥n vs Regresi√≥n

---

## Naturaleza del problema {.smaller}

### Clasificaci√≥n

- **Objetivo**: asignar una entrada a una o m√°s **clases discretas**.
- **Tipo de salida**: etiquetas categ√≥ricas (`'enfermo'`, `'sano'`, etc.) o c√≥digos (`0`, `1`, `2`...).
- **Ejemplos t√≠picos**:
  - Diagn√≥stico m√©dico (tumor benigno vs maligno).
  - Reconocimiento facial.
  - Detecci√≥n de spam en correos electr√≥nicos.

### Regresi√≥n

- **Objetivo**: predecir un **valor continuo** a partir de las caracter√≠sticas de entrada.
- **Tipo de salida**: num√©rico real.
- **Ejemplos t√≠picos**:
  - Predicci√≥n de dosis en radioterapia.
  - Estimaci√≥n de precios.
  - Predicci√≥n de temperatura.

---

## Estructura de modelos y activaciones

| Dimensi√≥n          | Clasificaci√≥n          | Regresi√≥n                           |
| ------------------ | ---------------------- | ----------------------------------- |
| Tipo de salida     | Etiqueta discreta      | Valor continuo                      |
| Funci√≥n de p√©rdida | Cross-entropy          | MSE / MAE                           |
| Activaci√≥n final   | Softmax / Sigmoid      | Lineal                              |
| M√©trica t√≠pica     | Accuracy, F1, AUC      | RMSE, R¬≤, MAE                       |
| Ejemplos           | Diagn√≥stico, detecci√≥n | Pron√≥stico, predicci√≥n cuantitativa |


# Aplicaci√≥n pr√°ctica de la inteligencia artificial en radioterapia
 
---

## Campos de aplicaci√≥n

- [**Registro deformable de imagen**]{.alert}
- Delimitiaci√≥n de estructuras (√≥rganos de riesgo y vol√∫menes blanco)
- Predicci√≥n de distribuciones de dosis
  - Previsi√≥n del impacto del tratamiento
  - Planificaci√≥n automatizada

:::{.callout-important icon="true"}
## Relevancia
El registro deformable puede servir como base para la soluci√≥n de otros problemas planteados en radioterapia.
:::

---

## Registro deformable de imagen {.smaller}

> **Definci√≥n** 
>
> El *registro de im√°genes* es el proceso de *alinear* dos o m√°s im√°genes obtenidas en diferentes momentos, desde diferentes dispositivos o con diferentes condiciones del paciente, de forma que *los mismos puntos anat√≥micos coincidan en todas ellas*. 
> 
> [Es **deformable** si se permiten **transformaciones locales no r√≠gidas**, como *compresiones, expansiones y desplazamientos* no uniformes]{.alert}.


[**Campos de aplicaci√≥n del registro deformable**]{.alert}

- **Radioterapia adaptativa**, donde se actualiza el plan seg√∫n cambios anat√≥micos del paciente.

- **Fusi√≥n de im√°genes multimodalidad** (CT, MRI, PET).

- **Propagaci√≥n de estructuras** entre distintos estudios de imagen.

- **Estimaci√≥n de dosis acumulada** a lo largo de m√∫ltiples fracciones.

---

![](images/CTSimulacion.png)

---

![](images/CBCT.png)

---

![](images/CampoDeformacion.png)

---

### M√©todos de realizaci√≥n del registro deformable

| M√©todo         | Precisi√≥n | Tiempo de c√°lculo | Multimodalidad | Aplicaci√≥n cl√≠nica             |
|----------------|-----------|-------------------|----------------|-------------------------------|
| Demons         | Media     | R√°pido            | No             | Frecuente                     |
| B-splines      | Alta      | Medio-lento       | Parcial        | Muy usada                     |
| MI             | Media     | Medio             | S√≠             | CT-MRI / PET                  |
| Deep Learning  | Alta      | Muy r√°pido        | Depende del modelo | En investigaci√≥n y precl√≠nica |

:::{.callout-note icon="true"}
## M√©todos tradicionales
Demons, B-splines y MI se implementan mediante *software convencional* y sirven de base para entrenar los modelos de Deep Learning.
:::


---

## {.smaller}

### üß† 3. M√©todos basados en aprendizaje profundo (Deep Learning DIR)

**Redes convolucionales (CNNs)**  
Aprenden directamente el campo de deformaci√≥n a partir de un conjunto grande de pares de im√°genes registradas.

Algunos ejemplos: *VoxelMorph*, *DeepReg*, *SynthMorph*.

**Ventajas:**

- Inferencia muy r√°pida (una vez entrenadas).
- Pueden generalizar bien si se entrena con suficiente diversidad de datos.

**Limitaciones:**

- Requieren bases de datos grandes y bien etiquetadas.
- Pueden ser una ‚Äúcaja negra‚Äù dif√≠cil de validar cl√≠nicamente.

---

## Comparativa de modelos de Deep Learning para DIR {.smaller}

::: columns
:::: column
### üß† VoxelMorph
- **Supervisi√≥n**: No supervisado  
- **Ventajas**:
  - Inferencia muy r√°pida
  - No requiere campos reales
- **Limitaciones**:
  - Menor adaptabilidad a dominios nuevos  
- **Uso t√≠pico**: Registro intra-modal (MRI, CT)  
- **Framework**: PyTorch / TensorFlow  
- [Repositorio](https://github.com/voxelmorph/voxelmorph)
::::

:::: column
### üß† DeepReg
- **Supervisi√≥n**: Supervisado / No / Semi  
- **Ventajas**:
  - Flexible y modular
  - Admite estructuras y m√°scaras  
- **Limitaciones**:
  - Mayor complejidad t√©cnica  
- **Uso t√≠pico**: Multimodal, longitudinal, supervisado  
- **Framework**: TensorFlow 2  
- [Repositorio](https://github.com/DeepRegNet/DeepReg)
::::
:::

---

## Comparativa de modelos de Deep Learning para DIR {.smaller}

::: columns
:::: column
### üß† SynthMorph
- **Supervisi√≥n**: Auto-supervisado  
- **Ventajas**:
  - No requiere datos reales registrados
  - √ötil para entrenamiento general
- **Limitaciones**:
  - Depende de la calidad de datos sint√©ticos  
- **Uso t√≠pico**: Preentrenamiento, escenarios sin datos anotados  
- **Framework**: PyTorch / TensorFlow  
- [Repositorio](https://github.com/voxelmorph/synthmorph)
::::
:::

---

## Delimitaci√≥n de vol√∫menes. M√©todos por software tradicional {.smaller}

::: {.columns}
:::: {.column}
### 1. Segmentaci√≥n por umbral

**Contexto cl√≠nico:** En radioterapia craneal (por ejemplo, para met√°stasis cerebrales o craneotom√≠as postquir√∫rgicas), se utilizan im√°genes de TC donde el hueso es claramente visible.

**Aplicaci√≥n:** Detecci√≥n autom√°tica de la calota craneal o columna vertebral con un umbral alto (ej. >300 HU).

**Limitaci√≥n:** No distingue bien hueso cortical de estructuras calcificadas o implantes met√°licos.
::::
:::: {.column}
![El usuario fija los extremos del intervalo de n√∫mero CT presente en la estructura.](images/Umbral.png)
::::
:::

---

## {.smaller}

::: {.columns}
:::: {.column}
### 2. Crecimiento de regiones
**Contexto cl√≠nico:** La vejiga u otros √≥rganos tiene un contorno bastante definido en TC.

**Aplicaci√≥n:** El software de planificaci√≥n puede sugerir autom√°ticamente el contorno de la vejiga basado en una semilla y par√°metros de intensidad.

**Limitaci√≥n:** Suele requerir postprocesado o correcciones manuales. Pobre desempe√±o si hay aire, cat√©teres o paredes irregulares.

::::
:::: {.column}
![La cruz indica la semilla fijada por el usuario y el control de deslizamiento los par√°metros de intensidad. Estos √∫ltimos suelen requerir reajustes iterativos](images/CrecimientoRegion.PNG)
::::
:::

---

## {.smaller}

::: {.columns}
:::: {.column}
### 3. Contornos activos

**Contexto cl√≠nico:** En tumores de ORL y otros, es crucial proteger la m√©dula espinal.

**Aplicaci√≥n:** Una vez identificada la m√©dula en cortes centrales, se usan *snakes* o algoritmos de contorno activo para propagarla en cortes adyacentes.

**Limitaci√≥n:** P√©rdida de exactitud si la m√©dula se curva o est√° comprimida por masa tumoral.
::::
:::: {.column}
![En ARIA estos algoritmos vienen prefijados para algunos √≥rganos concretos](images/Serpientes.png)
::::
:::

---

## Delimitaci√≥n de vol√∫menes mediante atlas {.smaller}

**Principio:**  
Se utilizan im√°genes previamente segmentadas (atlas) que se registran con la imagen del paciente.

**Pasos clave:**  
- Registro (r√≠gido o deformable) del atlas a la imagen del paciente.  
- Transferencia de las estructuras segmentadas.  
- Fusi√≥n de m√∫ltiples atlas (si se usan varios).

**Ventajas:**  
- Buen rendimiento si el atlas representa bien la anatom√≠a.  
- Permite segmentaci√≥n de estructuras complejas.

**Limitaciones:**  
- El registro deformable puede fallar en anatom√≠as alteradas (tumores, cirug√≠a).  
- Requiere base de datos curada y bien segmentada.  
- Lento en comparaci√≥n con m√©todos autom√°ticos modernos.

---

![](images/SmartSegmentation.png)

---

## Delimitaci√≥n de vol√∫menes mediante IA basada en CNNs{.smaller}

> La **delimitaci√≥n de estructuras** es un proceso similar a la **segmentaci√≥n de im√°genes**

:::{.callout-note icon="true"}
## Definici√≥n
La **segmentaci√≥n de im√°genes** es el proceso de dividir una imagen digital en regiones o segmentos significativos, agrupando los p√≠xeles que comparten caracter√≠sticas similares (como color, intensidad o textura) para facilitar su an√°lisis o interpretaci√≥n. En medicina, se utiliza para identificar y delimitar autom√°ticamente estructuras anat√≥micas o lesiones dentro de las im√°genes.
:::

:::{.callout-tip icon="true"}
## CNNs
Las **redes neuronales convolucionales** (*CNNs*) aplican filtros convolucionales para procesar im√°genes
:::

::: {.columns}
:::: {.column width="60%"}
### üß† CNNs en segmentaci√≥n m√©dica
::::
:::: {.column width="40%"}
**Entrada:**  üñºÔ∏è Imagen m√©dica (TC, RM, etc.)

**Salida:**  üéØ M√°scara de segmentaci√≥n:

- Binaria (√≥rgano vs. fondo)  
- Multiclase (varios √≥rganos)
::::
:::

---

## {.smaller}

üß± Arquitecturas m√°s comunes

  üîπ U-Net (Ronneberger et al., 2015): arquitectura sim√©trica en forma de **U**.

  - Tiene una fase de contracci√≥n (downsampling) y una fase de expansi√≥n (upsampling).
  - Las conexiones de *skip* entre niveles permiten recuperar detalles espaciales finos.
![](images/EthosU-net.png)

---

## {.smaller}

### üîπ Variantes modernas de CNNs para segmentaci√≥n m√©dica

- **3D U-Net**  
  Extiende U-Net a 3D para trabajar con vol√∫menes completos (TC/RM).

- **V-Net**  
  Similar a U-Net pero con convoluciones 3D desde cero.

- **nnU-Net**  
  Sistema autoajustable que adapta arquitectura y par√°metros autom√°ticamente.  
  _Est√°ndar de facto en competiciones._

- **Attention U-Net**  
  Introduce mecanismos de atenci√≥n para enfocarse en regiones relevantes.

- **Transformer-based (UNETR, TransUNet)**  
  Combinan CNNs con Transformers para contexto global.  
  M√°s potentes, pero requieren m√°s datos y tiempo.

---

### ‚öôÔ∏è Entrenamiento de modelos de segmentaci√≥n con CNNs

- **Datos de entrada:** Im√°genes m√©dicas (TC, RM, PET).  
- **Etiquetas (GT):** Segmentaciones manuales hechas por expertos.  
- **Funci√≥n de p√©rdida:**  
  - Dice loss  
  - Cross-Entropy  
- **Entrenamiento:**  
  - Requiere GPU  
  - Necesita grandes vol√∫menes de datos bien etiquetados

---

## {.smaller}

### üè• Ejemplos cl√≠nicos reales de uso de CNNs

| Regi√≥n anat√≥mica | Aplicaci√≥n cl√≠nica | Beneficio |
|------------------|--------------------|-----------|
| Pr√≥stata         | Delimitaci√≥n autom√°tica en RM para RT adaptativa | Ahorra tiempo, reduce variabilidad |
| Cabeza y cuello  | Gl√°ndulas salivales, m√©dula espinal, etc.        | Mejora precisi√≥n en regiones complejas |
| Mama             | Segmentaci√≥n de mama, pulm√≥n, coraz√≥n            | √ötil en VMAT e inspiraci√≥n controlada |
| Pulm√≥n           | Tumor en TC 4D                                    | Facilita RT adaptativa con control respiratorio |
| Cerebro (SRS)    | Lesiones m√∫ltiples en RM                          | Automatiza estructuras para radiocirug√≠a |

---

## {.smaller}

### üßæ Sistemas comerciales basados en CNN

| Sistema                    | Tecnolog√≠a base        | Caracter√≠sticas clave |
|----------------------------|------------------------|------------------------|
| **Mirada DLCExpert**       | CNN tipo U-Net         | Modelos para pr√≥stata, mama, cabeza y cuello |
| **MVision AI**             | CNN 3D + cloud         | Integraci√≥n con ARIA, RayStation, Eclipse |
| **Radformation AutoContour** | CNN U-Net 3D        | Web UI, modelos multisite |
| **Limbus AI**              | nnU-Net adaptado       | Modelos cl√≠nicamente validados, r√°pida implementaci√≥n |
| **Varian Ethos / Eclipse AI** | DL propietario     | Integraci√≥n directa en TPS (contornos iniciales) |
| **RayStation MRS (ML Seg)** | CNN 3D              | Permite entrenar modelos propios o usar preentrenados |

---

## Predicci√≥n de distribuciones de dosis

### Generalidades

- La predicci√≥n de dosis con IA consiste en estimar distribuciones 3D de dosis a partir de:
  - Im√°genes del paciente (TC, RM, etc.)
  - Contornos anat√≥micos (PTV, OARs)
  - Prescripci√≥n de dosis
- Puede emplearse como:
  - Punto de partida para planificaci√≥n
  - Referencia de la calidad de la planificaci√≥n
  - Elemento en el flujo de trabajo de la radioterapia adaptativa
---

#### Motivaci√≥n

- La planificaci√≥n manual es intensiva en tiempo y depende del operador
- Variabilidad interplanificador significativa
- Necesidad de adaptarse a cambios anat√≥micos en tratamientos largos
- La IA permite predecir mapas de dosis de forma r√°pida y consistente

---

#### Enfoques comunes

### Modelos supervisados

- Entrenamiento sobre pares (entrada: anatom√≠a / salida: dosis)
- **Redes CNN 2D/3D** y **U-Net** dominan el panorama actual
- Toman como entrada el volumen TC + contornos segmentados

### Modelos generativos

- **GANs (Generative Adversarial Networks)** y **VAEs**
- Capaces de generar mapas de dosis m√°s realistas

---

#### Aplicaciones cl√≠nicas

- **Planificaci√≥n autom√°tica**: predicci√≥n como plantilla inicial
- **Radioterapia adaptativa**: estimaci√≥n r√°pida de dosis diaria
- **Control de calidad**: comparaci√≥n dosis planificada vs IA
- **Optimizaci√≥n de planes** guiada por mapas IA

---

## {.smaller}

### RapidPlan

#### Planificaci√≥n mediante bases de conocimiento 

:::{.callout-note icon="true"}
## Naturaleza 

**RapidPlan** no es *Deep Learning* (no se entrena una red neuronal profunda), es una aplicaci√≥n de *Machine Learning*

- Se entrena con:
  - Curvas DVH de casos anteriores
  - Relaciones espaciales entre estructuras

:::

- Herramienta de Varian integrada en Eclipse‚Ñ¢
- Utiliza modelos estad√≠sticos entrenados con planes cl√≠nicos previos
- Predice curvas DVH para OARs y PTVs en base a la anatom√≠a del paciente
- Se usa para generar objetivos de optimizaci√≥n en la planificaci√≥n inversa

:::{.callout-important icon="true"}
## Objetivo 
Predecir **DVH esperados**, no predicir mapas de dosis voxel a voxel
:::

---

#### RapidPlan vs predicci√≥n de dosis con redes neuronales

| Caracter√≠stica       | RapidPlan                       | Deep Learning (U-Net, GAN)         |
|----------------------|----------------------------------|------------------------------------|
| Tipo de modelo       | Regresi√≥n multivariable          | Red neuronal profunda              |
| Datos de entrada     | Geometr√≠a + DVH                  | Im√°genes + contornos + dosis       |
| Salida               | DVH estimados                    | Mapa 3D de dosis voxel a voxel     |
| Uso cl√≠nico          | Optimizaci√≥n asistida            | Predicci√≥n directa / validaci√≥n    |
| Madurez comercial    | Alta (cl√≠nicamente implantado)   | Media (en expansi√≥n)               |

---

## {.smaller}

#### Entradas del modelo de RapidPlan‚Ñ¢

Los modelos se entrenan a partir de:

- Geometr√≠a de los campos de tratamiento
- Comportamiento del haz de fotones
- Geometr√≠a del target y niveles de dosis prescrita
- Heur√≠sticas cl√≠nicas (c√≥mo la disposici√≥n de campos influye en el ahorro de tejidos sanos)

#### ¬øQu√© es el GED (Geometry-based Expected Dose)?

- Es una representaci√≥n intermedia basada en la geometr√≠a del paciente
- Se calcula r√°pidamente a partir de:
  - El TC de planificaci√≥n
  - Las estructuras delineadas
  - La geometr√≠a de los campos
- Estima c√≥mo deber√≠a distribuirse la dosis bas√°ndose √∫nicamente en la geometr√≠a

---

## {.smaller} 

#### Aprendizaje estad√≠stico en RapidPlan‚Ñ¢

- Se aplica **an√°lisis de componentes principales (PCA)** a:
  - Histogramas DVH reales
  - Histogramas GED de entrenamiento
- Los coeficientes del PCA se introducen en modelos de **regresi√≥n supervisada**
- Esto permite predecir el DVH esperable en un nuevo paciente  
  a partir de su GED volume histogram

![La configuraci√≥n comienza por la selecci√≥n de casos (patolog√≠a, estrateg√≠a de tratamiento) y de las estructuras (PTVs y OARs) que se contemplaran en el modelo](images/ModelConf.png){fig-align="center"}

---

![El sistema considera los histogramas de cada √≥rgano para todos los casos](images/ModelMandibulaDVH.png){height="300px"}

![El sistema particulariza los histogramas considerando los volumenes en los que las proyecciones del campo de tratamiento intersecta el √≥rgano](images/ModelMandibulaInFieldDVH.png){height="300px"}

---

#### Predicci√≥n de DVH mediante regresi√≥n supervisada

1. Se calcula el GED volume histogram para cada estructura
2. Se asume que este est√° **altamente correlacionado** con el DVH real (por proximidad al target)

![Mediante un an√°lisis de componentes principales se realiza una regresi√≥n que relaciona el DVH en dosis real con el estimado en GED](images/ModelMandibulaRegressionPlot.png)

---

## {.smaller}

#### Salida del modelo: DVH + objetivos de optimizaci√≥n

- El modelo predice el DVH de las estructuras modeladas
- Genera los **objetivos de optimizaci√≥n** que permitir√°n a Eclipse alcanzar ese DVH
- As√≠ se estandariza la calidad del plan y se acelera la planificaci√≥n

![Dentro del rango de DVHs esperados RapidPlan fija su l√≠nea objetovo en el extremo inferior](images/ModeloEstimacionDVH.png)

---

## Generaci√≥n de CT sint√©ticos mediante inteligencia artificial

:::{.callout-important icon="true"}
## Necesidad de im√°genes sint√©ticas
- Radioterapia adaptativa y MRI-only workflows requieren mapas precisos de HU.
- CBCT y RM no son ideales para c√°lculo directo de dosis.
- Soluci√≥n: generar CT sint√©tico (sCT) mediante IA.
:::

- **CBCT**: baja calidad HU, artefactos de reconstrucci√≥n, escasa precisi√≥n dosim√©trica.
- **MRI**: Gran contraste anat√≥mico pero sin HU y con importantes artefactos geom√©tricos.

---

## {.smaller}

::: {.columns}
:::: {.column}
#### CBCT
**M√©todos**

- **CNN**: mapeo voxel a voxel CBCT ‚Üí sCT.
- **GAN**: mejoran realismo, generalizaci√≥n.
- **CycleGAN**: entrenamiento sin correspondencia exacta (non-paired).
- Nuevas arquitecturas: U-Net++, Vision Transformers.

::::
:::: {.column}
#### RMI
**M√©todos**

- **Single-sequence CNN**: T1/T2 ‚Üí HU.
- **Multi-sequence fusion**: mejora precisi√≥n.
- **GANs**: alta fidelidad visual y dosim√©trica.
- M√©todos directos (regresi√≥n HU) vs segmentaci√≥n-clasificaci√≥n.

**Retos t√©cnicos**

- Registro MRI-CT durante entrenamiento.
- Distorsiones geom√©tricas (B0, susceptibilidad).
- Variabilidad entre pacientes y esc√°neres.
::::
:::

#### Validaci√≥n dosim√©trica

- Comparaci√≥n DVHs: sCT vs CT real.
- Evaluaci√≥n con gamma index.
- Tolerancias cl√≠nicas para aceptaci√≥n.

---

## Limitaciones y reflexiones

::: {.callout-note icon="true"}
## Mirada al futuro
En unos a√±os, ser√° dif√≠cil concebir una radioterapia sin herramientas de IA. Y por eso es importante que todos ‚Äîno solo los ingenieros‚Äî entendamos c√≥mo funcionan.
:::

**No es magia**: La IA no es perfecta. Aprende de lo que le damos. Si los datos est√°n sesgados... el modelo tambi√©n.

**Responsabilidad profesional**: Aunque tengamos herramientas autom√°ticas, seguimos siendo los responsables de supervisar, validar y decidir.

**√âtica y transparencia**: Breve menci√≥n a la necesidad de trazabilidad, validaci√≥n, y el papel del profesional humano.

