---
title: "Inteligencia artificial en radioterapia"
subtitle: Simposio de Técnicos. Congreso conjunto SEFM SEPR. Toledo 2025
format: 
  clean-revealjs:
    logo: images/2505-SEFM-SEPR_Toledo_400x122-400x122.png
    footer: "IA en Radioterapia"
  pptx: {}
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
author:
  - name: César Rodríguez
    email: cesar.rodriguez@salud.madrid.org
    affiliations: Hospital Universitario de Fuenlabrada
css: styles.css
---


# ¿Qué es la inteligencia artificial?

---

## 1. Definición de IA {.smaller}

> La [**inteligencia artificial**]{.alert} (IA) es una rama de la informática que [**permite a las máquinas imitar funciones cognitivas**]{.alert} humanas como aprender, razonar, resolver problemas o tomar decisiones.

### Ejemplos cotidianos de IA

- Filtros de spam en el correo.
- Recomendaciones en Netflix o Spotify.
- Traductores automáticos.
- Chatbots.
- Detección de tumores en mamografías.

:::{.callout-note icon="true"}
## Cotidaneidad de la IA
Convivimos con la IA todos los días, incluso sin darnos cuenta. En medicina, puede ser una gran aliada.
:::

---

## 2. ¿En qué se diferencia de un software tradicional?

| Característica         | Software tradicional             | Inteligencia Artificial                |
|------------------------|----------------------------------|----------------------------------------|
| Instrucciones          | Programadas explícitamente       | Aprende de datos                       |
| Capacidad de adaptación| Fija                             | Se adapta con entrenamiento            |
| Ejemplo en radioterapia| Cálculo de dosis con fórmulas    | Segmentación automática                |{.smaller}

> ✅ **Analogía culinaria**:  
> El software tradicional es como una receta;  
> la IA es como un cocinero que aprende probando.

---

## 3. Tipos principales de IA{.smaller}

::: {.columns}
:::: {.column}
### IA simbólica

- Basada en reglas lógicas.
- Utiliza sistemas expertos.
- Es la forma más antigua de IA.

### Machine Learning (ML)

- Aprende patrones a partir de datos.
- Necesita entrenamiento con muchos ejemplos.
- Se ha convertido en el núcleo de la IA moderna.

### Deep Learning (DL)

- Subconjunto de ML.
- Utiliza redes neuronales profundas.
- Muy eficaz en imagen médica.

::::
:::: {.column .bottom-align}
![](images/MachineLearning_DeepLearning.png)
::::
:::

# Ejemplos

---
 
### Software tradicional. Cálculo de la dosis

::: {.smaller-columns}
::: {.columns}
:::: {.column width="30%"}
![](images/CalculoDosis.png)
::::
:::: {.column width="70%"}
$$
\begin{aligned}
\Omega_\gamma \cdot \nabla \Phi_\gamma(r, \Omega_\gamma, E_\gamma) = \\
\rho_e(r) \int_0^\infty \int_{4\pi} \tilde{\sigma}_{C,\gamma}(E'_\gamma, E_\gamma, \Omega'_\gamma \cdot \Omega_\gamma) 
\Phi_\gamma(r, \Omega'_\gamma, E'_\gamma) d\Omega'_\gamma dE'_\gamma
\\
- \rho_e(r) \sigma_{\text{totC},\gamma}(E_\gamma) \Phi_\gamma(r, \Omega_\gamma, E_\gamma)
\end{aligned}
$$

Ecuación de Boltzmann de transporte de fotones

:::: 
:::
:::

- Problemas complejos que se pueden reducir a algoritmos programables
- La velocidad de cálculo de la máquina supera completamente lo que es realizable por un ser humano

:::{.callout-tip icon="true"}
## Paradigma 
Sabemos cómo funciona y **funciona** (*para lo que está programado*)
:::

---

### IA tradicional (árboles lógicos). Reconocimiento de patrones

::: {.columns}
:::: {.column width="50%"}
![Reconocimiento de caracteres y facial](images/handwrittendigits.png)
::::
:::: {.column width="50%"}
![](images/Jose.jpg){height="100px"} ![](images/Cesar.jpg){height="100px"} ![](images/Gema.jpg){height="100px"} ![](images/Eva.jpg){height="100px"} 

:::: 
:::

- La complejidad del problema crece tan rápidamente que son necesarias estructuras muy complicadas y muchos recursos.
- El humano supera con cierta facilidad los resultados de la máquina

:::{.callout-important icon="true"}
## Paradigma 
Sabemos cómo funciona pero **no funciona** 
:::

# ¿Cómo podemos hacer *pensar* a una máquina?

---

## Problemas de minimización
### Fundamentos matemáticos para el entrenamiento de sistemas

```{python}
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Datos simulados: precio de vivienda (en miles de euros) vs superficie (m²)
np.random.seed(123)
m_true = 3.  # precio por m² en miles de euros
b_true = 100.0  # precio base (mínimo, en miles de euros)
x = np.linspace(30, 150, 20)  # superficies entre 30 m² y 150 m²
y = m_true * x + b_true + np.random.normal(scale=20.0, size=len(x))  # precios con ruido

# Rango de valores de pendiente (precio por m²)
m_values = np.linspace(m_true - 2, m_true + 2, 50)
J_values = [np.sum((y - (m * x + b_true))**2) for m in m_values]

# Crear figura con subgráficos
fig = make_subplots(rows=1, cols=2, subplot_titles=["Ajuste lineal: Precio vs Superficie", "Función de coste J(m)"])

# Añadir trazas fijas (siempre visibles)
fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name='Datos reales', marker=dict(color='black')), row=1, col=1)
fig.add_trace(go.Scatter(x=m_values, y=J_values, mode='lines', name='Función de coste J(m)', line=dict(color='black')), row=1, col=2)

# Trazas dinámicas iniciales
m0 = m_values[0]
y_fit0 = m0 * x + b_true
J0 = J_values[0]

ajuste_inicial = go.Scatter(x=x, y=y_fit0, mode='lines', name='Ajuste lineal', line=dict(color='red'))
punto_J = go.Scatter(x=[m0], y=[J0], mode='markers', name='Valor de J', marker=dict(color='red', size=10))

fig.add_trace(ajuste_inicial, row=1, col=1)
fig.add_trace(punto_J, row=1, col=2)

# Frames para animar
frames = []

for i, m in enumerate(m_values):
    y_fit = m * x + b_true
    J = J_values[i]
    frame = go.Frame(
        data=[
            # Puntos originales (subplot 1,1)
            go.Scatter(x=x, y=y, mode='markers', marker=dict(color='black'),
                       xaxis='x1', yaxis='y1'),

            # Línea de ajuste (subplot 1,1)
            go.Scatter(x=x, y=y_fit, mode='lines', line=dict(color='red'),
                       xaxis='x1', yaxis='y1'),

            # Curva de función de coste J(m) (subplot 1,2)
            go.Scatter(x=m_values, y=J_values, mode='lines', line=dict(color='black'),
                       xaxis='x2', yaxis='y2'),

            # Punto rojo J(m) (subplot 1,2)
            go.Scatter(x=[m], y=[J], mode='markers', marker=dict(color='red', size=10),
                       xaxis='x2', yaxis='y2'),
        ],
        name=str(round(m, 2))
    )
    frames.append(frame)

# Slider
steps = [dict(method="animate",
              args=[[str(round(m, 2))],
                    dict(mode="immediate",
                         frame=dict(duration=0, redraw=True),
                         transition=dict(duration=0))],
              label=str(round(m, 2)))
         for m in m_values]

sliders = [dict(
    steps=steps,
    transition=dict(duration=0),
    x=0.1,
    y=0,
    currentvalue=dict(font=dict(size=16), prefix="Precio por m² = ", visible=True, xanchor='center'),
    len=0.8
)]

# Aplicar layout con solo el slider
fig.update_layout(
    sliders=sliders,
    height=500,
    width=1000
)

# Asignar los frames directamente
fig.frames = frames

# Etiquetas de ejes
fig.update_xaxes(title_text="Superficie (m²)", row=1, col=1)
fig.update_yaxes(title_text="Precio (miles de euros)", row=1, col=1)
fig.update_xaxes(title_text="Precio por m² (miles de euros)", row=1, col=2)
fig.update_yaxes(title_text="J(m)", row=1, col=2)

fig.show()

```
---

### Elementos clave 

- El sistema establece el modelo minimizando una ***función de coste*** que tiene que ser definida previamente

:::{.callout-tip icon="true"}
## Cálculos de minimización 
La minimización es proceso programable por los procedimientos de software tradicional
:::

:::{.callout-important icon="true"}
## Importancia del modelo
El modelo nos permite **hacer predicciones** reduciendo la influencia de variables ocultas
:::

#### Dificultades con modelos que dependen de varias variables
- No todas las variables que podemos introducir en el modelo lo *sujetan* con la misma intensidad
- Algunas variables presentan correlaciones, es decir, la variación de una implica la variación de otra.


---

### Varias variables con diferentes correlaciones

```{python}

import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots

np.random.seed(123)

# Simulación 1: Precio vs Superficie (alta correlación)
m1_true = 3.0  # mil €/m²
b1_true = 100.0
x1 = np.linspace(50, 150, 20)  # m²
y1 = m1_true * x1 + b1_true + np.random.normal(scale=15.0, size=len(x1))

# Simulación 2: Precio vs Altura (menor correlación)
m2_true = 5.0  # mil €/planta
b2_true = 200.0
x2 = np.linspace(1, 20, 20)  # plantas
y2 = m2_true * x2 + b2_true + np.random.normal(scale=40.0, size=len(x2))

# Ajustes
m1_fit, b1_fit = np.polyfit(x1, y1, 1)
y1_fit = m1_fit * x1 + b1_fit

m2_fit, b2_fit = np.polyfit(x2, y2, 1)
y2_fit = m2_fit * x2 + b2_fit

# Funciones de coste con rango de 5 unidades
m_values1 = np.linspace(m1_fit - 2.5, m1_fit + 2.5, 100)
J_values1 = [np.sum((y1 - (m * x1 + b1_true))**2) for m in m_values1]

m_values2 = np.linspace(m2_fit - 2.5, m2_fit + 2.5, 100)
J_values2 = [np.sum((y2 - (m * x2 + b2_true))**2) for m in m_values2]

# Crear figura con 4 subgráficos
fig = make_subplots(rows=2, cols=2, subplot_titles=[
    "Precio vs Superficie",
    "Función de coste J(m): Superficie",
    "Precio vs Altura",
    "Función de coste J(m): Altura"
])

# Arriba izquierda: Ajuste superficie
fig.add_trace(go.Scatter(x=x1, y=y1, mode='markers', name='Datos superficie', marker=dict(color='black')), row=1, col=1)
fig.add_trace(go.Scatter(x=x1, y=y1_fit, mode='lines', name='Ajuste superficie', line=dict(color='red')), row=1, col=1)

# Arriba derecha: Coste superficie
fig.add_trace(go.Scatter(x=m_values1, y=J_values1, mode='lines', name='J(m): superficie', line=dict(color='black')), row=1, col=2)

# Abajo izquierda: Ajuste altura
fig.add_trace(go.Scatter(x=x2, y=y2, mode='markers', name='Datos altura', marker=dict(color='black')), row=2, col=1)
fig.add_trace(go.Scatter(x=x2, y=y2_fit, mode='lines', name='Ajuste altura', line=dict(color='red')), row=2, col=1)

# Abajo derecha: Coste altura
fig.add_trace(go.Scatter(x=m_values2, y=J_values2, mode='lines', name='J(m): altura', line=dict(color='black')), row=2, col=2)

# Etiquetas
fig.update_xaxes(title_text="Superficie (m²)", row=1, col=1)
fig.update_yaxes(title_text="Precio (miles de €)", row=1, col=1)
fig.update_xaxes(title_text="Pendiente m (mil €/m²)", row=1, col=2)
fig.update_yaxes(title_text="J(m)", row=1, col=2)

fig.update_xaxes(title_text="Altura (plantas)", row=2, col=1)
fig.update_yaxes(title_text="Precio (miles de €)", row=2, col=1)
fig.update_xaxes(title_text="Pendiente m (mil €/planta)", row=2, col=2)
fig.update_yaxes(title_text="J(m)", row=2, col=2)

fig.update_yaxes(range=[0, 1.e6], row=1, col=2)
fig.update_yaxes(range=[0, 1.e6], row=2, col=2)

fig.update_layout(
    height=650,
    width=800,
    showlegend=False
)

fig.show()


```

---

### **Overfitting** (sobreajuste)

```{python}

import numpy as np
import plotly.graph_objects as go

# Datos originales: precio vs superficie
np.random.seed(123)
m_true = 3.0  # mil €/m²
b_true = 100.0
x = np.linspace(50, 150, 20)
y = m_true * x + b_true + np.random.normal(scale=15.0, size=len(x))

# Ajuste polinómico de grado alto (overfitting)
degree = len(x)
coefs = np.polyfit(x, y, degree)
poly = np.poly1d(coefs)

# Evaluar el modelo en una malla más fina
x_fine = np.linspace(40, 160, 500)
y_poly = poly(x_fine)

# Crear figura
fig = go.Figure()

# Datos
fig.add_trace(go.Scatter(x=x, y=y, mode='markers', name='Datos', marker=dict(color='black')))

# Ajuste polinómico (overfitting)
fig.add_trace(go.Scatter(x=x_fine, y=y_poly, mode='lines', name='Modelo sobreajustado', line=dict(color='red', dash='dot')))

fig.update_yaxes(range=[200, 600])

# Layout
fig.update_layout(
    xaxis_title="Superficie (m²)",
    yaxis_title="Precio (miles de €)",
    width=800,
    height=500
)

fig.show()

```

- El modelo predice muy bien lo que ha aprendido
- Pierde la capacidad de predecir situaciones no entrenadas

# Ejemplos de minimización. Aplicación a la radioterapia

## Optimación de fluencias para tratamientos VMAT

![Tratamiento adyuvante de un hemicuello. Dosis de prescripción 66 Gy al primario y 56.1 Gy a las cadenas ganglionares](images/testORL.png)

---

##

![Definición del problema de optimización](images/DefinicionObjetivosOptimizacionVMAT.png)

> La **función de coste no** es **única**.  
> Hay muchas funciones de coste que producen una solución válida;  
> se introduce variabilidad entre los planificadores.  
> Es difícil saber si la planificación está realmente optimizada.  

---

## {.smaller}
#### Correlaciones entre parámetros

![El tiroides en parte esta incluido en el PTV de cadenas](images/TiroidesRealista.PNG)

---

## {.smaller}
#### Correlaciones entre parámetros

![Si forzamos el tiroides afectamos al PTV](images/TiroidesForzado.PNG)

# ¿Cómo funciona una red neuronal artificial?

---

## {.smaller}

### Analogía 
🧠 **Red neuronal artificial =** 🔧 **Fábrica en cadena**

Cada capa recibe una entrada, la procesa y pasa el resultado a la siguiente.

Cada neurona hace una operación: pondera entradas, suma, aplica una función.

### Estructura típica

::: {.columns}
:::: {.column width="50%"}
- **Capa de entrada**: recibe la imagen o los datos.  
- **Capas ocultas**: transforman progresivamente la información.  
  - Convolución  
  - Activación (triggers)  
  - Normalización / reducción  
- **Capa de salida**: genera una predicción.
::::
:::: {.column width="50%"}
![](images/FullyConnectedLayers.webp){fig-align="center" }
::::
:::

---

### Detalles de las capas

#### 🔸 Capa de convolución *(solo en redes de imagen)*

- Aplica pequeños filtros que se desplazan por la imagen.  

![](images/diagrama_convolucion.png)

- Cada filtro detecta un patrón específico: borde, textura, forma…  
- Resultado: un mapa de activación que destaca ese patrón.  

---

## {.smaller}

#### Visualización de la salida de algunos filtros de convolución


::: {.columns}
:::: {.column width="50%"}
![](images/BordesHorizontales.webp){fig-align="right" height="100px"}
::::
:::: {.column width="50%"}
![](images/BordesVerticales.webp){fig-align="left" height="100px"}
::::
:::

::: {.columns}
:::: {.column width="60%"}
![](images/SalidaFiltrosConvolucionPrimeraCapa.png){fig-align="center"}
::::
:::: {.column width="40%"}
📌 

- En el diseño del modelo se fija el número de filtros de convolución
- Los detalles de cada filtro, sus valores concretos, se establecen durante el entrenamiento, son parámetros ajustables del modelo
- En general la salida de los filtros de convolución pueden tener una interpretación no trivial para un ser humano
::::
:::

---

### 🔸 b) Función de activación (“trigger”)

- Imita el disparo neuronal: una función no lineal ***decide si [la neurona se activa]{.alert}***.  
- Ejemplo: función ReLU (Rectified Linear Unit):  
  - Salida = 0 si entrada < 0  
  - Salida = entrada si entrada ≥ 0  

::: {.columns}
:::: {.column}
```{python}
import numpy as np
import matplotlib.pyplot as plt

# Definimos la función ReLU
def relu(x):
    return np.maximum(0, x)

# Creamos un conjunto de valores
x = np.linspace(-10, 10, 1000)
y = relu(x)

# Graficamos
plt.figure(figsize=(4, 2.7))
plt.plot(x, y, label="ReLU(x)")
plt.axhline(0, color='gray', lw=0.5)
plt.axvline(0, color='gray', lw=0.5)
plt.title("Función ReLU")
plt.xlabel("x")
plt.ylabel("ReLU(x)")
plt.grid(True)
plt.legend()
plt.show()

```
::::
:::: {.column}
```{python}
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from scipy.signal import convolve2d

# === Paso 1: Cargar y preparar la imagen ===
img_path = "images/Eva.jpg"  # Reemplaza con la ruta a tu imagen
img = Image.open(img_path).convert("L")  # Escala de grises
img = img.resize((256, 256))             # Redimensiona para facilidad
img_array = np.array(img) / 255.0        # Normaliza a [0,1]

# === Paso 2: Filtro de convolución (bordes verticales estilo Sobel) ===
filtro = np.array([[1, 0, -1],
                   [2, 0, -2],
                   [1, 0, -1]])

# Aplicar convolución 2D
conv_output = convolve2d(img_array, filtro, mode='same', boundary='symm')

# === Paso 3: Aplicar ReLU ===
relu_output = np.maximum(0, conv_output)

# === Paso 4: Mostrar los resultados ===
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.imshow(img_array, cmap='gray')
plt.title("Imagen original")
plt.axis('off')

plt.subplot(1, 3, 2)
plt.imshow(conv_output, cmap='gray')
plt.title("Convolución (bordes)")
plt.axis('off')

plt.subplot(1, 3, 3)
plt.imshow(relu_output, cmap='gray')
plt.title("Tras ReLU")
plt.axis('off')

plt.tight_layout()
plt.show()

```
::::
:::

- Esto permite que la red aprenda relaciones complejas, no lineales.

---

### 🔸 c) Pooling (reducción)

- Reduce la dimensión de la información manteniendo lo importante.  
- Equivalente a hacer un ***[zoom out]{.alert}: pierde detalle, gana eficiencia***.  

::: {.columns}
:::: {.column}
![](images/PoolingMaxScheme.png)
::::
:::: {.column}
```{python}
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from scipy.signal import convolve2d
from skimage.measure import block_reduce

# === Paso 1: Cargar y preparar la imagen ===
img_path = "images/Eva.jpg"  # Reemplaza con tu imagen
img = Image.open(img_path).convert("L")
img = img.resize((256, 256))  # Tamaño fijo
img_array = np.array(img) / 255.0

# === Paso 2: Aplicar filtro de bordes (Sobel horizontal) ===
filtro = np.array([[-1, 0, 1],
                   [-2, 0, 2],
                   [-1, 0, 1]])

conv_output = convolve2d(img_array, filtro, mode='same', boundary='symm')

# === Paso 3: Activación ReLU ===
relu_output = np.maximum(0, conv_output)

# === Paso 4: MaxPooling 4x4 ===
# Reduce cada bloque de 4x4 a 1x1 (efecto "zoom out")
pooled_output = block_reduce(relu_output, block_size=(4, 4), func=np.max)

# === Paso 5: Visualización comparativa ===
plt.figure(figsize=(10, 5))

# Subgráfica 1: ReLU output original
plt.subplot(1, 2, 1)
plt.imshow(relu_output, cmap='gray')
plt.title("ReLU (alta resolución)")
plt.axis('off')

# Subgráfica 2: ReLU tras MaxPooling (escalado al mismo tamaño para comparación)
plt.subplot(1, 2, 2)
plt.imshow(pooled_output, cmap='gray', extent=[0, relu_output.shape[1], relu_output.shape[0], 0])
plt.title("Tras MaxPooling 4x4")
plt.axis('off')

plt.tight_layout()
plt.show()

```
::::
:::

# ¿Cómo aprende una red neuronal?

---

### 🔹 a) Entrenamiento = Minimizar un error

- Se pasa una imagen por la red → predicción.  
- Se compara con la etiqueta real → función de pérdida.  
- Se ajustan los pesos de las conexiones para reducir el error.  
- Este proceso se repite con millones de imágenes.  

:::{.callout-tip icon="true"}
## Entrenamiento de una red neuronal
Entrenar una red neuronal es como hacer IMRT: queremos encontrar la mejor combinación de pesos (parámetros) que cumplan unos objetivos y minimicen una función de coste.
:::

---

## Tipos de Aprendizaje en Machine Learning

::: {.columns}
:::: {.column}
### ✅ Aprendizaje Supervisado
- Se entrena con **datos etiquetados**
- Cada entrada tiene una **respuesta conocida**
- El modelo aprende a **predecir la etiqueta** a partir de la entrada
::::
:::: {.column}
![](images/Chest-x-ray-images-from-Kaggle-dataset-a-Normal-lung-image-b-Bacterial-pneumonia.png)
::::
:::

---

### 🔄 Aprendizaje No Supervisado 
Se entrena con datos sin etiquetas

El objetivo es descubrir patrones ocultos, como agrupaciones o estructuras

::: {.columns}
:::: {.column}
![](images/george_clooney5.png){fig-align="center" height="300px"}
::::
:::: {.column}
![](images/cluster_personas_objetos.jpeg){fig-align="center" height="300px"}
::::
:::

---

### 🧪 Aprendizaje Auto-supervisado 

Genera sus propias etiquetas a partir de los datos

Diseña tareas auxiliares para aprender representaciones útiles

:::{.callout-tip icon="true"}
## Ejemplo de aprendizaje auto-supervisado
Enmascarar parte de una imagen y entrenar al modelo a reconstruirla
:::

---

## {.smaller} 

#### Resumen sobre los tipos de aprendizaje en IA

| Tipo               | Etiquetas reales requeridas     | Objetivo principal                 | Ejemplos comunes                                 |
|--------------------|----------------------------------|------------------------------------|--------------------------------------------------|
| Supervisado        | Sí                              | Clasificación, regresión           | Diagnóstico médico, detección de fallos          |
| No supervisado     | No                              | Agrupamiento, reducción            | Análisis exploratorio, clustering                |
| Auto-supervisado   | No (usa etiquetas derivadas)    | Aprendizaje de representaciones    | Preentrenamiento, NLP, visión artificial         |

---

## {.smaller}

#### Ejemplo: entrenamiento de una red neuronal de reconocimiento facial

Cuatro clases, 150 archivos de 128x128 en color, 

**Arquitectura de la red**

| Layer (type)                    | Output Shape           |       Param # |
|---------------------------------|------------------------|---------------|
| conv2d (Conv2D)                 | (None, 126, 126, 32)   |           896 |
| max_pooling2d (MaxPooling2D)    | (None, 63, 63, 32)     |             0 |
| conv2d_1 (Conv2D)               | (None, 61, 61, 64)     |        18,496 |
| max_pooling2d_1 (MaxPooling2D)  | (None, 30, 30, 64)     |             0 |
| flatten (Flatten)               | (None, 57600)          |             0 |
| dense (Dense)                   | (None, 128)            |     7,372,928 |
| dropout (Dropout)               | (None, 128)            |             0 |
| dense_1 (Dense)                 | (None, 4)              |           516 |

- Número de parámetros ajustables (Memoria): **[7,392,836]{.alert} (28.20 MB)**
- Tiempo de entrenamiento en un Apple Silicon M2: **11.63 secs**

[**Exactitud del modelo: 96.67%**]{.alert}

---

:::{.callout-important icon="true"}
## Degeneración del problema
El número de parámetros a ajustar es tan elevado que no es un problema sencillo de resolver. Necesitamos que el software de entrenamiento siga alguna estrategia que nos guie hacia una solución válida.
:::


### 🔹 b) Optimización por retropropagación

- Se calcula el error.  
- Se propaga hacia atrás a través de la red.  
- Se ajustan los pesos paso a paso con técnicas como descenso de gradiente, actuando fundamentalmente sobre los parámetros que se identifican más relevantes.


# 🧠 Modelos de Inteligencia Artificial: Clasificación vs Regresión

---

## Naturaleza del problema {.smaller}

### Clasificación

- **Objetivo**: asignar una entrada a una o más **clases discretas**.
- **Tipo de salida**: etiquetas categóricas (`'enfermo'`, `'sano'`, etc.) o códigos (`0`, `1`, `2`...).
- **Ejemplos típicos**:
  - Diagnóstico médico (tumor benigno vs maligno).
  - Reconocimiento facial.
  - Detección de spam en correos electrónicos.

### Regresión

- **Objetivo**: predecir un **valor continuo** a partir de las características de entrada.
- **Tipo de salida**: numérico real.
- **Ejemplos típicos**:
  - Predicción de dosis en radioterapia.
  - Estimación de precios.
  - Predicción de temperatura.

---

## Estructura de modelos y activaciones

| Dimensión          | Clasificación          | Regresión                           |
| ------------------ | ---------------------- | ----------------------------------- |
| Tipo de salida     | Etiqueta discreta      | Valor continuo                      |
| Función de pérdida | Cross-entropy          | MSE / MAE                           |
| Activación final   | Softmax / Sigmoid      | Lineal                              |
| Métrica típica     | Accuracy, F1, AUC      | RMSE, R², MAE                       |
| Ejemplos           | Diagnóstico, detección | Pronóstico, predicción cuantitativa |


# Aplicación práctica de la inteligencia artificial en radioterapia
 
---

## Campos de aplicación

- [**Registro deformable de imagen**]{.alert}
- Delimitiación de estructuras (órganos de riesgo y volúmenes blanco)
- Predicción de distribuciones de dosis
  - Previsión del impacto del tratamiento
  - Planificación automatizada

:::{.callout-important icon="true"}
## Relevancia
El registro deformable puede servir como base para la solución de otros problemas planteados en radioterapia.
:::

---

## Registro deformable de imagen {.smaller}

> **Definción** 
>
> El *registro de imágenes* es el proceso de *alinear* dos o más imágenes obtenidas en diferentes momentos, desde diferentes dispositivos o con diferentes condiciones del paciente, de forma que *los mismos puntos anatómicos coincidan en todas ellas*. 
> 
> [Es **deformable** si se permiten **transformaciones locales no rígidas**, como *compresiones, expansiones y desplazamientos* no uniformes]{.alert}.


[**Campos de aplicación del registro deformable**]{.alert}

- **Radioterapia adaptativa**, donde se actualiza el plan según cambios anatómicos del paciente.

- **Fusión de imágenes multimodalidad** (CT, MRI, PET).

- **Propagación de estructuras** entre distintos estudios de imagen.

- **Estimación de dosis acumulada** a lo largo de múltiples fracciones.

---

![](images/CTSimulacion.png)

---

![](images/CBCT.png)

---

![](images/CampoDeformacion.png)

---

### Métodos de realización del registro deformable

| Método         | Precisión | Tiempo de cálculo | Multimodalidad | Aplicación clínica             |
|----------------|-----------|-------------------|----------------|-------------------------------|
| Demons         | Media     | Rápido            | No             | Frecuente                     |
| B-splines      | Alta      | Medio-lento       | Parcial        | Muy usada                     |
| MI             | Media     | Medio             | Sí             | CT-MRI / PET                  |
| Deep Learning  | Alta      | Muy rápido        | Depende del modelo | En investigación y preclínica |

:::{.callout-note icon="true"}
## Métodos tradicionales
Demons, B-splines y MI se implementan mediante *software convencional* y sirven de base para entrenar los modelos de Deep Learning.
:::


---

## {.smaller}

### 🧠 3. Métodos basados en aprendizaje profundo (Deep Learning DIR)

**Redes convolucionales (CNNs)**  
Aprenden directamente el campo de deformación a partir de un conjunto grande de pares de imágenes registradas.

Algunos ejemplos: *VoxelMorph*, *DeepReg*, *SynthMorph*.

**Ventajas:**

- Inferencia muy rápida (una vez entrenadas).
- Pueden generalizar bien si se entrena con suficiente diversidad de datos.

**Limitaciones:**

- Requieren bases de datos grandes y bien etiquetadas.
- Pueden ser una “caja negra” difícil de validar clínicamente.

---

## Comparativa de modelos de Deep Learning para DIR {.smaller}

::: columns
:::: column
### 🧠 VoxelMorph
- **Supervisión**: No supervisado  
- **Ventajas**:
  - Inferencia muy rápida
  - No requiere campos reales
- **Limitaciones**:
  - Menor adaptabilidad a dominios nuevos  
- **Uso típico**: Registro intra-modal (MRI, CT)  
- **Framework**: PyTorch / TensorFlow  
- [Repositorio](https://github.com/voxelmorph/voxelmorph)
::::

:::: column
### 🧠 DeepReg
- **Supervisión**: Supervisado / No / Semi  
- **Ventajas**:
  - Flexible y modular
  - Admite estructuras y máscaras  
- **Limitaciones**:
  - Mayor complejidad técnica  
- **Uso típico**: Multimodal, longitudinal, supervisado  
- **Framework**: TensorFlow 2  
- [Repositorio](https://github.com/DeepRegNet/DeepReg)
::::
:::

---

## Comparativa de modelos de Deep Learning para DIR {.smaller}

::: columns
:::: column
### 🧠 SynthMorph
- **Supervisión**: Auto-supervisado  
- **Ventajas**:
  - No requiere datos reales registrados
  - Útil para entrenamiento general
- **Limitaciones**:
  - Depende de la calidad de datos sintéticos  
- **Uso típico**: Preentrenamiento, escenarios sin datos anotados  
- **Framework**: PyTorch / TensorFlow  
- [Repositorio](https://github.com/voxelmorph/synthmorph)
::::
:::

---

## Delimitación de volúmenes. Métodos por software tradicional {.smaller}

::: {.columns}
:::: {.column}
### 1. Segmentación por umbral

**Contexto clínico:** En radioterapia craneal (por ejemplo, para metástasis cerebrales o craneotomías postquirúrgicas), se utilizan imágenes de TC donde el hueso es claramente visible.

**Aplicación:** Detección automática de la calota craneal o columna vertebral con un umbral alto (ej. >300 HU).

**Limitación:** No distingue bien hueso cortical de estructuras calcificadas o implantes metálicos.
::::
:::: {.column}
![El usuario fija los extremos del intervalo de número CT presente en la estructura.](images/Umbral.png)
::::
:::

---

## {.smaller}

::: {.columns}
:::: {.column}
### 2. Crecimiento de regiones
**Contexto clínico:** La vejiga u otros órganos tiene un contorno bastante definido en TC.

**Aplicación:** El software de planificación puede sugerir automáticamente el contorno de la vejiga basado en una semilla y parámetros de intensidad.

**Limitación:** Suele requerir postprocesado o correcciones manuales. Pobre desempeño si hay aire, catéteres o paredes irregulares.

::::
:::: {.column}
![La cruz indica la semilla fijada por el usuario y el control de deslizamiento los parámetros de intensidad. Estos últimos suelen requerir reajustes iterativos](images/CrecimientoRegion.PNG)
::::
:::

---

## {.smaller}

::: {.columns}
:::: {.column}
### 3. Contornos activos

**Contexto clínico:** En tumores de ORL y otros, es crucial proteger la médula espinal.

**Aplicación:** Una vez identificada la médula en cortes centrales, se usan *snakes* o algoritmos de contorno activo para propagarla en cortes adyacentes.

**Limitación:** Pérdida de exactitud si la médula se curva o está comprimida por masa tumoral.
::::
:::: {.column}
![En ARIA estos algoritmos vienen prefijados para algunos órganos concretos](images/Serpientes.png)
::::
:::

---

## Delimitación de volúmenes mediante atlas {.smaller}

**Principio:**  
Se utilizan imágenes previamente segmentadas (atlas) que se registran con la imagen del paciente.

**Pasos clave:**  
- Registro (rígido o deformable) del atlas a la imagen del paciente.  
- Transferencia de las estructuras segmentadas.  
- Fusión de múltiples atlas (si se usan varios).

**Ventajas:**  
- Buen rendimiento si el atlas representa bien la anatomía.  
- Permite segmentación de estructuras complejas.

**Limitaciones:**  
- El registro deformable puede fallar en anatomías alteradas (tumores, cirugía).  
- Requiere base de datos curada y bien segmentada.  
- Lento en comparación con métodos automáticos modernos.

---

![](images/SmartSegmentation.png)

---

## Delimitación de volúmenes mediante IA basada en CNNs{.smaller}

> La **delimitación de estructuras** es un proceso similar a la **segmentación de imágenes**

:::{.callout-note icon="true"}
## Definición
La **segmentación de imágenes** es el proceso de dividir una imagen digital en regiones o segmentos significativos, agrupando los píxeles que comparten características similares (como color, intensidad o textura) para facilitar su análisis o interpretación. En medicina, se utiliza para identificar y delimitar automáticamente estructuras anatómicas o lesiones dentro de las imágenes.
:::

:::{.callout-tip icon="true"}
## CNNs
Las **redes neuronales convolucionales** (*CNNs*) aplican filtros convolucionales para procesar imágenes
:::

::: {.columns}
:::: {.column width="60%"}
### 🧠 CNNs en segmentación médica
::::
:::: {.column width="40%"}
**Entrada:**  🖼️ Imagen médica (TC, RM, etc.)

**Salida:**  🎯 Máscara de segmentación:

- Binaria (órgano vs. fondo)  
- Multiclase (varios órganos)
::::
:::

---

## {.smaller}

🧱 Arquitecturas más comunes

  🔹 U-Net (Ronneberger et al., 2015): arquitectura simétrica en forma de **U**.

  - Tiene una fase de contracción (downsampling) y una fase de expansión (upsampling).
  - Las conexiones de *skip* entre niveles permiten recuperar detalles espaciales finos.
![](images/EthosU-net.png)

---

## {.smaller}

### 🔹 Variantes modernas de CNNs para segmentación médica

- **3D U-Net**  
  Extiende U-Net a 3D para trabajar con volúmenes completos (TC/RM).

- **V-Net**  
  Similar a U-Net pero con convoluciones 3D desde cero.

- **nnU-Net**  
  Sistema autoajustable que adapta arquitectura y parámetros automáticamente.  
  _Estándar de facto en competiciones._

- **Attention U-Net**  
  Introduce mecanismos de atención para enfocarse en regiones relevantes.

- **Transformer-based (UNETR, TransUNet)**  
  Combinan CNNs con Transformers para contexto global.  
  Más potentes, pero requieren más datos y tiempo.

---

### ⚙️ Entrenamiento de modelos de segmentación con CNNs

- **Datos de entrada:** Imágenes médicas (TC, RM, PET).  
- **Etiquetas (GT):** Segmentaciones manuales hechas por expertos.  
- **Función de pérdida:**  
  - Dice loss  
  - Cross-Entropy  
- **Entrenamiento:**  
  - Requiere GPU  
  - Necesita grandes volúmenes de datos bien etiquetados

---

## {.smaller}

### 🏥 Ejemplos clínicos reales de uso de CNNs

| Región anatómica | Aplicación clínica | Beneficio |
|------------------|--------------------|-----------|
| Próstata         | Delimitación automática en RM para RT adaptativa | Ahorra tiempo, reduce variabilidad |
| Cabeza y cuello  | Glándulas salivales, médula espinal, etc.        | Mejora precisión en regiones complejas |
| Mama             | Segmentación de mama, pulmón, corazón            | Útil en VMAT e inspiración controlada |
| Pulmón           | Tumor en TC 4D                                    | Facilita RT adaptativa con control respiratorio |
| Cerebro (SRS)    | Lesiones múltiples en RM                          | Automatiza estructuras para radiocirugía |

---

## {.smaller}

### 🧾 Sistemas comerciales basados en CNN

| Sistema                    | Tecnología base        | Características clave |
|----------------------------|------------------------|------------------------|
| **Mirada DLCExpert**       | CNN tipo U-Net         | Modelos para próstata, mama, cabeza y cuello |
| **MVision AI**             | CNN 3D + cloud         | Integración con ARIA, RayStation, Eclipse |
| **Radformation AutoContour** | CNN U-Net 3D        | Web UI, modelos multisite |
| **Limbus AI**              | nnU-Net adaptado       | Modelos clínicamente validados, rápida implementación |
| **Varian Ethos / Eclipse AI** | DL propietario     | Integración directa en TPS (contornos iniciales) |
| **RayStation MRS (ML Seg)** | CNN 3D              | Permite entrenar modelos propios o usar preentrenados |

---

## Predicción de distribuciones de dosis

### Generalidades

- La predicción de dosis con IA consiste en estimar distribuciones 3D de dosis a partir de:
  - Imágenes del paciente (TC, RM, etc.)
  - Contornos anatómicos (PTV, OARs)
  - Prescripción de dosis
- Puede emplearse como:
  - Punto de partida para planificación
  - Referencia de la calidad de la planificación
  - Elemento en el flujo de trabajo de la radioterapia adaptativa
---

#### Motivación

- La planificación manual es intensiva en tiempo y depende del operador
- Variabilidad interplanificador significativa
- Necesidad de adaptarse a cambios anatómicos en tratamientos largos
- La IA permite predecir mapas de dosis de forma rápida y consistente

---

#### Enfoques comunes

### Modelos supervisados

- Entrenamiento sobre pares (entrada: anatomía / salida: dosis)
- **Redes CNN 2D/3D** y **U-Net** dominan el panorama actual
- Toman como entrada el volumen TC + contornos segmentados

### Modelos generativos

- **GANs (Generative Adversarial Networks)** y **VAEs**
- Capaces de generar mapas de dosis más realistas

---

#### Aplicaciones clínicas

- **Planificación automática**: predicción como plantilla inicial
- **Radioterapia adaptativa**: estimación rápida de dosis diaria
- **Control de calidad**: comparación dosis planificada vs IA
- **Optimización de planes** guiada por mapas IA

---

## {.smaller}

### RapidPlan

#### Planificación mediante bases de conocimiento 

:::{.callout-note icon="true"}
## Naturaleza 

**RapidPlan** no es *Deep Learning* (no se entrena una red neuronal profunda), es una aplicación de *Machine Learning*

- Se entrena con:
  - Curvas DVH de casos anteriores
  - Relaciones espaciales entre estructuras

:::

- Herramienta de Varian integrada en Eclipse™
- Utiliza modelos estadísticos entrenados con planes clínicos previos
- Predice curvas DVH para OARs y PTVs en base a la anatomía del paciente
- Se usa para generar objetivos de optimización en la planificación inversa

:::{.callout-important icon="true"}
## Objetivo 
Predecir **DVH esperados**, no predicir mapas de dosis voxel a voxel
:::

---

#### RapidPlan vs predicción de dosis con redes neuronales

| Característica       | RapidPlan                       | Deep Learning (U-Net, GAN)         |
|----------------------|----------------------------------|------------------------------------|
| Tipo de modelo       | Regresión multivariable          | Red neuronal profunda              |
| Datos de entrada     | Geometría + DVH                  | Imágenes + contornos + dosis       |
| Salida               | DVH estimados                    | Mapa 3D de dosis voxel a voxel     |
| Uso clínico          | Optimización asistida            | Predicción directa / validación    |
| Madurez comercial    | Alta (clínicamente implantado)   | Media (en expansión)               |

---

## {.smaller}

#### Entradas del modelo de RapidPlan™

Los modelos se entrenan a partir de:

- Geometría de los campos de tratamiento
- Comportamiento del haz de fotones
- Geometría del target y niveles de dosis prescrita
- Heurísticas clínicas (cómo la disposición de campos influye en el ahorro de tejidos sanos)

#### ¿Qué es el GED (Geometry-based Expected Dose)?

- Es una representación intermedia basada en la geometría del paciente
- Se calcula rápidamente a partir de:
  - El TC de planificación
  - Las estructuras delineadas
  - La geometría de los campos
- Estima cómo debería distribuirse la dosis basándose únicamente en la geometría

---

## {.smaller} 

#### Aprendizaje estadístico en RapidPlan™

- Se aplica **análisis de componentes principales (PCA)** a:
  - Histogramas DVH reales
  - Histogramas GED de entrenamiento
- Los coeficientes del PCA se introducen en modelos de **regresión supervisada**
- Esto permite predecir el DVH esperable en un nuevo paciente  
  a partir de su GED volume histogram

![La configuración comienza por la selección de casos (patología, estrategía de tratamiento) y de las estructuras (PTVs y OARs) que se contemplaran en el modelo](images/ModelConf.png){fig-align="center"}

---

![El sistema considera los histogramas de cada órgano para todos los casos](images/ModelMandibulaDVH.png){height="300px"}

![El sistema particulariza los histogramas considerando los volumenes en los que las proyecciones del campo de tratamiento intersecta el órgano](images/ModelMandibulaInFieldDVH.png){height="300px"}

---

#### Predicción de DVH mediante regresión supervisada

1. Se calcula el GED volume histogram para cada estructura
2. Se asume que este está **altamente correlacionado** con el DVH real (por proximidad al target)

![Mediante un análisis de componentes principales se realiza una regresión que relaciona el DVH en dosis real con el estimado en GED](images/ModelMandibulaRegressionPlot.png)

---

## {.smaller}

#### Salida del modelo: DVH + objetivos de optimización

- El modelo predice el DVH de las estructuras modeladas
- Genera los **objetivos de optimización** que permitirán a Eclipse alcanzar ese DVH
- Así se estandariza la calidad del plan y se acelera la planificación

![Dentro del rango de DVHs esperados RapidPlan fija su línea objetovo en el extremo inferior](images/ModeloEstimacionDVH.png)

---

## Generación de CT sintéticos mediante inteligencia artificial

:::{.callout-important icon="true"}
## Necesidad de imágenes sintéticas
- Radioterapia adaptativa y MRI-only workflows requieren mapas precisos de HU.
- CBCT y RM no son ideales para cálculo directo de dosis.
- Solución: generar CT sintético (sCT) mediante IA.
:::

- **CBCT**: baja calidad HU, artefactos de reconstrucción, escasa precisión dosimétrica.
- **MRI**: Gran contraste anatómico pero sin HU y con importantes artefactos geométricos.

---

## {.smaller}

::: {.columns}
:::: {.column}
#### CBCT
**Métodos**

- **CNN**: mapeo voxel a voxel CBCT → sCT.
- **GAN**: mejoran realismo, generalización.
- **CycleGAN**: entrenamiento sin correspondencia exacta (non-paired).
- Nuevas arquitecturas: U-Net++, Vision Transformers.

::::
:::: {.column}
#### RMI
**Métodos**

- **Single-sequence CNN**: T1/T2 → HU.
- **Multi-sequence fusion**: mejora precisión.
- **GANs**: alta fidelidad visual y dosimétrica.
- Métodos directos (regresión HU) vs segmentación-clasificación.

**Retos técnicos**

- Registro MRI-CT durante entrenamiento.
- Distorsiones geométricas (B0, susceptibilidad).
- Variabilidad entre pacientes y escáneres.
::::
:::

#### Validación dosimétrica

- Comparación DVHs: sCT vs CT real.
- Evaluación con gamma index.
- Tolerancias clínicas para aceptación.

---

## Limitaciones y reflexiones

::: {.callout-note icon="true"}
## Mirada al futuro
En unos años, será difícil concebir una radioterapia sin herramientas de IA. Y por eso es importante que todos —no solo los ingenieros— entendamos cómo funcionan.
:::

**No es magia**: La IA no es perfecta. Aprende de lo que le damos. Si los datos están sesgados... el modelo también.

**Responsabilidad profesional**: Aunque tengamos herramientas automáticas, seguimos siendo los responsables de supervisar, validar y decidir.

**Ética y transparencia**: Breve mención a la necesidad de trazabilidad, validación, y el papel del profesional humano.

