{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import libraries such as TensorFlow, Keras, NumPy, Matplotlib, and OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for face recognition using deep learning\n",
    "import tensorflow as tf  # TensorFlow for deep learning\n",
    "from tensorflow import keras  # Keras for building and training models\n",
    "import numpy as np  # NumPy for numerical operations\n",
    "import matplotlib.pyplot as plt  # Matplotlib for visualization\n",
    "import cv2  # OpenCV for image processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess the Dataset\n",
    "Load the face dataset, resize images, normalize pixel values, and split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the face dataset\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "import os  # For file and directory operations\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"path_to_face_dataset\"  # Replace with the actual dataset path\n",
    "\n",
    "# Initialize lists to store images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load images and labels from the dataset directory\n",
    "for label in os.listdir(dataset_path):\n",
    "    label_path = os.path.join(dataset_path, label)\n",
    "    if os.path.isdir(label_path):\n",
    "        for image_file in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_file)\n",
    "            image = cv2.imread(image_path)  # Read the image\n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, (128, 128))  # Resize image to 128x128\n",
    "                images.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "images = np.array(images, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Normalize pixel values to the range [0, 1]\n",
    "images = images / 255.0\n",
    "\n",
    "# Encode labels as integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the datasets\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Testing labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the CNN Model\n",
    "Define a CNN architecture using Keras Sequential API with layers like Conv2D, MaxPooling2D, Flatten, Dense, and Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model using Keras Sequential API\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = Sequential([\n",
    "    # First convolutional layer with ReLU activation and max pooling\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Second convolutional layer with ReLU activation and max pooling\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Third convolutional layer with ReLU activation and max pooling\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Flatten the feature maps into a 1D vector\n",
    "    Flatten(),\n",
    "\n",
    "    # Fully connected dense layer with ReLU activation\n",
    "    Dense(128, activation='relu'),\n",
    "\n",
    "    # Dropout layer to prevent overfitting\n",
    "    Dropout(0.5),\n",
    "\n",
    "    # Output layer with softmax activation for multi-class classification\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Compile the model with an optimizer, loss function, and metrics, then train it using the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with an optimizer, loss function, and metrics\n",
    "model.compile(\n",
    "    optimizer='adam',  # Adam optimizer\n",
    "    loss='sparse_categorical_crossentropy',  # Sparse categorical crossentropy loss for multi-class classification\n",
    "    metrics=['accuracy']  # Track accuracy during training\n",
    ")\n",
    "\n",
    "# Train the model using the training dataset\n",
    "history = model.fit(\n",
    "    X_train,  # Training images\n",
    "    y_train,  # Training labels\n",
    "    validation_split=0.2,  # Use 20% of the training data for validation\n",
    "    epochs=20,  # Number of epochs\n",
    "    batch_size=32,  # Batch size\n",
    "    verbose=1  # Print progress during training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "Evaluate the trained model on the test dataset and display metrics such as accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on the test dataset\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "# Print the test accuracy and loss\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Plot training and validation accuracy over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Face Recognition on Test Images\n",
    "Use the trained model to predict and recognize faces in test images, displaying the results with Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform face recognition on test images\n",
    "def recognize_faces(test_images, model, label_encoder):\n",
    "    \"\"\"\n",
    "    Predict and recognize faces in test images using the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "    - test_images: Array of test images.\n",
    "    - model: Trained CNN model.\n",
    "    - label_encoder: LabelEncoder instance used for encoding labels.\n",
    "    \n",
    "    Returns:\n",
    "    - predictions: List of predicted labels for the test images.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    for img in test_images:\n",
    "        # Expand dimensions to match the input shape of the model\n",
    "        img_expanded = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        # Predict the class probabilities\n",
    "        probabilities = model.predict(img_expanded)\n",
    "        \n",
    "        # Get the class with the highest probability\n",
    "        predicted_class = np.argmax(probabilities, axis=1)[0]\n",
    "        \n",
    "        # Decode the predicted class to the original label\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_class])[0]\n",
    "        predictions.append(predicted_label)\n",
    "    return predictions\n",
    "\n",
    "# Select a few test images for visualization\n",
    "num_test_images = 5\n",
    "selected_test_images = X_test[:num_test_images]\n",
    "selected_test_labels = y_test[:num_test_images]\n",
    "\n",
    "# Perform face recognition on the selected test images\n",
    "predicted_labels = recognize_faces(selected_test_images, model, label_encoder)\n",
    "\n",
    "# Display the test images along with their predicted and true labels\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(num_test_images):\n",
    "    plt.subplot(1, num_test_images, i + 1)\n",
    "    plt.imshow(selected_test_images[i])\n",
    "    plt.title(f\"Predicted: {predicted_labels[i]}\\nTrue: {label_encoder.inverse_transform([selected_test_labels[i]])[0]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
